{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Carga de dataset (CSV de ejemplo no productivo)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Propósito de este Notebook\n",
        "\n",
        "**Importante:** Este notebook es solo para **documentación y exploración inicial**. No se utiliza en el pipeline de producción.\n",
        "\n",
        "El pipeline MLOps (`run_pipeline.py`) carga los datos automáticamente usando `ft_engineering.py`, que lee directamente `Base_de_datos.csv` y aplica preprocesamiento.\n",
        "\n",
        "### Uso recomendado:\n",
        "\n",
        "- **Validación inicial**: Verificar que el dataset tenga la estructura correcta\n",
        "- **Exploración rápida**: Ver distribuciones, estadísticas básicas, valores nulos\n",
        "- **Documentación**: Entender el formato y contenido de los datos antes de entrenar\n",
        "- **Desarrollo local**: Probar transformaciones antes de integrarlas al pipeline\n",
        "\n",
        "### En producción:\n",
        "\n",
        "En un entorno real, los datos provendrían de:\n",
        "- Data Warehouse (DWH)\n",
        "- Data Lake\n",
        "- Bases de datos relacionales (PostgreSQL, MySQL)\n",
        "- APIs REST\n",
        "- Sistemas de mensajería (Kafka, RabbitMQ)\n",
        "\n",
        "Este CSV es solo un ejemplo para demostración."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Ruta al dataset\n",
        "data_path = Path('../../Base_de_datos.csv')\n",
        "\n",
        "# Verificar que exista\n",
        "if not data_path.exists():\n",
        "    raise FileNotFoundError(f'Dataset no encontrado en {data_path.resolve()}')\n",
        "\n",
        "# Cargar datos\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "print(f\"Datos cargados correctamente desde: {data_path.resolve()}\")\n",
        "print(f\"Forma del dataset: {df.shape[0]} filas × {df.shape[1]} columnas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mostrar primeras filas\n",
        "print(\"Primeras 5 filas del dataset:\\n\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"\\nÚltimas 5 filas del dataset:\\n\")\n",
        "display(df.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Información del dataset\n",
        "print(\"ℹInformación general del dataset:\\n\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nTipos de datos:\\n\")\n",
        "display(df.dtypes)\n",
        "\n",
        "print(\"\\nDimensiones:\")\n",
        "print(f\"  - Filas: {df.shape[0]}\")\n",
        "print(f\"  - Columnas: {df.shape[1]}\")\n",
        "print(f\"  - Total de celdas: {df.shape[0] * df.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estadísticas descriptivas\n",
        "print(\"Estadísticas descriptivas:\\n\")\n",
        "display(df.describe())\n",
        "\n",
        "print(\"\\nDistribución de la variable objetivo 'quality':\\n\")\n",
        "if 'quality' in df.columns:\n",
        "    display(df['quality'].value_counts().sort_index())\n",
        "    print(f\"\\nRango: {df['quality'].min()} - {df['quality'].max()}\")\n",
        "else:\n",
        "    print(\"Advertencia: No se encontró la columna 'quality'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar valores nulos\n",
        "print(\"Verificación de valores nulos:\\n\")\n",
        "null_counts = df.isnull().sum()\n",
        "null_percentages = (df.isnull().sum() / len(df)) * 100\n",
        "\n",
        "null_summary = pd.DataFrame({\n",
        "    'Valores Nulos': null_counts,\n",
        "    'Porcentaje (%)': null_percentages.round(2)\n",
        "})\n",
        "\n",
        "display(null_summary[null_summary['Valores Nulos'] > 0])\n",
        "\n",
        "if null_summary['Valores Nulos'].sum() == 0:\n",
        "    print(\"Excelente! No hay valores nulos en el dataset\")\n",
        "else:\n",
        "    print(f\"Se encontraron {null_summary['Valores Nulos'].sum()} valores nulos\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"NOTA IMPORTANTE:\")\n",
        "print(\"=\"*60)\n",
        "print(\"Este notebook es solo para exploración inicial.\")\n",
        "print(\"El pipeline de producción usa ft_engineering.py para:\")\n",
        "print(\"  - Cargar automáticamente Base_de_datos.csv\")\n",
        "print(\"  - Aplicar preprocesamiento (imputación, codificación, escalado)\")\n",
        "print(\"  - Generar preprocessor.joblib\")\n",
        "print(\"  - Entrenar modelos con validación cruzada\")\n",
        "print(\"\\n¡No es necesario ejecutar este notebook para el pipeline!\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
